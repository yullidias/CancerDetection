{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção automática de câncer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualização\n",
    "\n",
    "O câncer de mama é o de maior incidência em mulheres do Brasil. De acordo com o INCA (Instituto Nacional de Câncer) em 2017 de todas as neoplasias que levaram a óbito em mulheres, 16,1%  foram com localização primária na mama. Em 2018 esse número subiu para 29,5%, mostrando como esse é um problema que possui uma curva ascendente. Para diagnósticos precoces a chance de cura é alta chegando até 95%.\n",
    "\n",
    "Para a investigação, além do exame clínico das mamas, exames de imagem podem ser recomendados, como mamografia, ultrassonografia ou ressonância magnética. A confirmação diagnóstica só é feita, porém, por meio da biópsia, sendo necessária a retirada de um fragmento do nódulo em uma pequena cirurgia. \n",
    "\n",
    "Como qualquer cirurgia, existem o risco da operação. Dessa forma, um meio de diagnosticar de forma menos agressiva se o nódulo é maligno ou benigno seria analisando suas características, verificando os valores encontrados nos exames prévios. Além disso, o processo de diagnóstico seria muito mais rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem\n",
    "\n",
    "A base de dados utilizada nesse trabalho foi obtida no [Kaggle](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data). Essa base é consiste em um conjunto de instâncias compostas por atributos númericos e classe alvo. A partir dessas instâncias serão criados e avaliados modelos para detecção automática de câncer, ou seja, prever se um nódulo é maligno ou benigno. Os atributos e a classe alvo são:\n",
    "\n",
    "### Atributos: \n",
    "* id: identificador\n",
    "* radius_mean: distância média do ponto central até o perimetro\n",
    "* texture_mean: desvio padrão dos valores da escala de cinza\n",
    "* perimeter_mean: tamanho médio do tumor central\n",
    "* area_mean: área média do tumor\n",
    "* smoothness_mean: média da varição dos comprimentos de raio\n",
    "* compactness_mean: perimeter_mean^2 / area_mean - 1.0\n",
    "* concavity_mean: média de gravidade de porções côncavas do contorno\n",
    "* concave points_mean: média do número de gravidade de porções côncavas do contorno\n",
    "* symmetry_mean: média de simetria\n",
    "* fractal_dimension_mean: média para \"aproximação do contorno\" - 1\n",
    "* radius_se: erro para radius_mean\n",
    "* texture_ses: erro para texture_mean\n",
    "* perimeter_se: perimetro\n",
    "* area_se: erro área\n",
    "* smoothness_se: error para smoothness_mean\n",
    "* compactness_se: error para compactness_mean\n",
    "* concavity_se: erro para concavity_mean\n",
    "* concave points_se: erro para concave points_mean\n",
    "* symmetry_se:  erra para simetria\n",
    "* fractal_dimension_se: erro para fractal_dimension_mean\n",
    "* radius_worst: média dos três maiores valores do raio\n",
    "* texture_worst: média dos três maiores valores de texture_mean\n",
    "* area_worst: média dos três maiores valores de área\n",
    "* smoothness_worst: média dos três maiores valores de smoothness_mean\n",
    "* compactness_worst: média dos três maiores valores de compactness_mean\n",
    "* concavity_worst: média dos três maiores valores de concave points_mean\n",
    "* concave points_worst: média dos três maiores valores de concavity_mean\n",
    "* fractal_dimension_worst: média dos três maiores valores de fractal_dimension_mean\n",
    "\n",
    "### Classe\n",
    "* diagnosis: O diagnóstico dos tecidos mamários(M = maligno, B = benigno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalhos Relacionados\n",
    "\n",
    "### Applications of Machine Learning in Cancer Prediction and Prognosis\n",
    "\n",
    "Em 2006, Joseph A. Cruz escreveu um artigo com um estudo sobre as aplicações de aprendizado de máquina na previsão e prognóstico do câncer. Foi realizada uma ampla pesquisa sobre os diferentes tipos de métodos de aprendizado de máquina que estão sendo usados, os tipos de dados que estão sendo integrados e o desempenho desses métodos na previsão e prognóstico do câncer.\n",
    "\n",
    "Foram comparados árvore de decisão, naive bayes, KNN, redes neurais, SVM e algoritmos genéticos, considerando vários estudos de caso. \n",
    "\n",
    "Um dos problemas mais comuns observados entre os estudos pesquisados foram a falta de atenção ao tamanho dos dados e validação. Isso mostra como é importante ter um conjunto de dados suficientemente grande que possa ser particionado em conjuntos de treinamento e teste disjuntos ou submetido a alguma forma razoável de n-fold cross-validation para conjuntos de dados menores.\n",
    "\n",
    "Foi mostrado uma tabela com os métodos de aprendizado de máquina usados na previsão de câncer, mostrando os tipos de câncer, parâmetros clínicos, escolha do algoritmo, desempenho e tipo de dados de treinamento.\n",
    "\n",
    "O artigo conclui dizendo como as redes neurais ainda são predominantes mas uma variedade crescente de estratégias alternativas de aprendizado de máquina estão sendo utilizadas e sendo aplicadas a muitos tipos de câncer.\n",
    "\n",
    "### An expert system for detection of breast cancer based on association rules and neural network\n",
    "\n",
    "Murat Karabatak escreveu um artigo em 2009 apresentando um sistema especialista para detecção de câncer de mama com base em regras de associação (AR) e rede neural (NN). Nesse estudo as AR são utilizadas para reduzir a dimensão da base de dados enquanto a rede neural é utilizada na classificação. \n",
    "\n",
    "São utilizados duas técnicas diferentes de AR para eliminar entradas desnecessárias. A técnica AR1 usa todos os parâmetros de entrada e todos os seus registros para encontrar relações entre eles. Se forem encontradas regras que tenham valor de suporte suficiente e alto valor de confiança, é possível eliminar algumas entradas. Já o AR2 usa todos os parâmetros de entrada, mas nem todos os seus registros.\n",
    "\n",
    "Para a rede neural é utilizado um multi-layer perceptron, sendo sua entrada as features obtidas pela AR.\n",
    "\n",
    "Foram realizados testes com NN, NN + AR1 e NN + AR2, e os resultados obtidos foram:\n",
    "\n",
    "| Classificador | Épocas | Classificações Corretas | Classificações erradas | Taxa de classificação correta |\n",
    "|---------------|--------|-------------------------|------------------------|-------------------------------|\n",
    "|      NN       |   61   |           216           |           11           |              95,2             |\n",
    "|    AR1 + NN   |   44   |           221           |            6           |              97,4             |\n",
    "|    AR2 + NN   |   33   |           217           |           10           |              95,6             |\n",
    "\n",
    "Os melhores resultados foram obtidos com AR1 + NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.300100</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.450</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.52490</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.250</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.14420</td>\n",
       "      <td>0.25760</td>\n",
       "      <td>0.37840</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.710</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.093660</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.16540</td>\n",
       "      <td>0.36820</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.093530</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.17030</td>\n",
       "      <td>0.54010</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.085430</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.18530</td>\n",
       "      <td>1.05800</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.020</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.05697</td>\n",
       "      <td>...</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.11810</td>\n",
       "      <td>0.15510</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.780</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.099540</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>0.06082</td>\n",
       "      <td>...</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.13960</td>\n",
       "      <td>0.56090</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07800</td>\n",
       "      <td>...</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.10370</td>\n",
       "      <td>0.39030</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.850</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.099380</td>\n",
       "      <td>0.053640</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.05338</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.19240</td>\n",
       "      <td>0.23220</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.730</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.080250</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.07682</td>\n",
       "      <td>...</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.16510</td>\n",
       "      <td>0.77250</td>\n",
       "      <td>0.69430</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.540</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.073640</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>0.07077</td>\n",
       "      <td>...</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.65770</td>\n",
       "      <td>0.70260</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.680</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.05922</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.14640</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.07356</td>\n",
       "      <td>...</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.42330</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.810</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.05395</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.15120</td>\n",
       "      <td>0.31500</td>\n",
       "      <td>0.53720</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.066640</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.05766</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.045680</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.06811</td>\n",
       "      <td>...</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>...</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.340</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.097560</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.07032</td>\n",
       "      <td>...</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.59540</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.086320</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.05278</td>\n",
       "      <td>...</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.14010</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.31550</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.650</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.14570</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.06330</td>\n",
       "      <td>...</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.18050</td>\n",
       "      <td>0.35780</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.09564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17.140</td>\n",
       "      <td>16.40</td>\n",
       "      <td>116.00</td>\n",
       "      <td>912.7</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.22760</td>\n",
       "      <td>0.222900</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>0.3040</td>\n",
       "      <td>0.07413</td>\n",
       "      <td>...</td>\n",
       "      <td>21.40</td>\n",
       "      <td>152.40</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.15450</td>\n",
       "      <td>0.39490</td>\n",
       "      <td>0.38530</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.4066</td>\n",
       "      <td>0.10590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14.580</td>\n",
       "      <td>21.53</td>\n",
       "      <td>97.41</td>\n",
       "      <td>644.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.18680</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.06924</td>\n",
       "      <td>...</td>\n",
       "      <td>33.21</td>\n",
       "      <td>122.40</td>\n",
       "      <td>896.9</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.66430</td>\n",
       "      <td>0.55390</td>\n",
       "      <td>0.27010</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.12750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.610</td>\n",
       "      <td>20.25</td>\n",
       "      <td>122.10</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.09440</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.077310</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>0.05699</td>\n",
       "      <td>...</td>\n",
       "      <td>27.26</td>\n",
       "      <td>139.90</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>0.13380</td>\n",
       "      <td>0.21170</td>\n",
       "      <td>0.34460</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.07421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.300</td>\n",
       "      <td>25.27</td>\n",
       "      <td>102.40</td>\n",
       "      <td>732.4</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.16970</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.087510</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.06540</td>\n",
       "      <td>...</td>\n",
       "      <td>36.71</td>\n",
       "      <td>149.30</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>0.16410</td>\n",
       "      <td>0.61100</td>\n",
       "      <td>0.63350</td>\n",
       "      <td>0.20240</td>\n",
       "      <td>0.4027</td>\n",
       "      <td>0.09876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17.570</td>\n",
       "      <td>15.05</td>\n",
       "      <td>115.00</td>\n",
       "      <td>955.1</td>\n",
       "      <td>0.09847</td>\n",
       "      <td>0.11570</td>\n",
       "      <td>0.098750</td>\n",
       "      <td>0.079530</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.06149</td>\n",
       "      <td>...</td>\n",
       "      <td>19.52</td>\n",
       "      <td>134.90</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.28120</td>\n",
       "      <td>0.24890</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.07919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>7.691</td>\n",
       "      <td>25.44</td>\n",
       "      <td>48.34</td>\n",
       "      <td>170.4</td>\n",
       "      <td>0.08668</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.092520</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.2037</td>\n",
       "      <td>0.07751</td>\n",
       "      <td>...</td>\n",
       "      <td>31.89</td>\n",
       "      <td>54.49</td>\n",
       "      <td>223.6</td>\n",
       "      <td>0.15960</td>\n",
       "      <td>0.30640</td>\n",
       "      <td>0.33930</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>11.540</td>\n",
       "      <td>14.44</td>\n",
       "      <td>74.65</td>\n",
       "      <td>402.9</td>\n",
       "      <td>0.09984</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>0.025940</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.06782</td>\n",
       "      <td>...</td>\n",
       "      <td>19.68</td>\n",
       "      <td>78.78</td>\n",
       "      <td>457.8</td>\n",
       "      <td>0.13450</td>\n",
       "      <td>0.21180</td>\n",
       "      <td>0.17970</td>\n",
       "      <td>0.06918</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>14.470</td>\n",
       "      <td>24.99</td>\n",
       "      <td>95.81</td>\n",
       "      <td>656.4</td>\n",
       "      <td>0.08837</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>0.06341</td>\n",
       "      <td>...</td>\n",
       "      <td>31.73</td>\n",
       "      <td>113.50</td>\n",
       "      <td>808.9</td>\n",
       "      <td>0.13400</td>\n",
       "      <td>0.42020</td>\n",
       "      <td>0.40400</td>\n",
       "      <td>0.12050</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>14.740</td>\n",
       "      <td>25.42</td>\n",
       "      <td>94.70</td>\n",
       "      <td>668.6</td>\n",
       "      <td>0.08275</td>\n",
       "      <td>0.07214</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>0.030270</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.05680</td>\n",
       "      <td>...</td>\n",
       "      <td>32.29</td>\n",
       "      <td>107.40</td>\n",
       "      <td>826.4</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>0.13760</td>\n",
       "      <td>0.16110</td>\n",
       "      <td>0.10950</td>\n",
       "      <td>0.2722</td>\n",
       "      <td>0.06956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>13.210</td>\n",
       "      <td>28.06</td>\n",
       "      <td>84.88</td>\n",
       "      <td>538.4</td>\n",
       "      <td>0.08671</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.05781</td>\n",
       "      <td>...</td>\n",
       "      <td>37.17</td>\n",
       "      <td>92.48</td>\n",
       "      <td>629.6</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.13810</td>\n",
       "      <td>0.10620</td>\n",
       "      <td>0.07958</td>\n",
       "      <td>0.2473</td>\n",
       "      <td>0.06443</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>13.870</td>\n",
       "      <td>20.70</td>\n",
       "      <td>89.77</td>\n",
       "      <td>584.8</td>\n",
       "      <td>0.09578</td>\n",
       "      <td>0.10180</td>\n",
       "      <td>0.036880</td>\n",
       "      <td>0.023690</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.06688</td>\n",
       "      <td>...</td>\n",
       "      <td>24.75</td>\n",
       "      <td>99.17</td>\n",
       "      <td>688.6</td>\n",
       "      <td>0.12640</td>\n",
       "      <td>0.20370</td>\n",
       "      <td>0.13770</td>\n",
       "      <td>0.06845</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.08492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>13.620</td>\n",
       "      <td>23.23</td>\n",
       "      <td>87.19</td>\n",
       "      <td>573.2</td>\n",
       "      <td>0.09246</td>\n",
       "      <td>0.06747</td>\n",
       "      <td>0.029740</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>0.1664</td>\n",
       "      <td>0.05801</td>\n",
       "      <td>...</td>\n",
       "      <td>29.09</td>\n",
       "      <td>97.58</td>\n",
       "      <td>729.8</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.07174</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.06953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>10.320</td>\n",
       "      <td>16.35</td>\n",
       "      <td>65.31</td>\n",
       "      <td>324.9</td>\n",
       "      <td>0.09434</td>\n",
       "      <td>0.04994</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.06201</td>\n",
       "      <td>...</td>\n",
       "      <td>21.77</td>\n",
       "      <td>71.12</td>\n",
       "      <td>384.9</td>\n",
       "      <td>0.12850</td>\n",
       "      <td>0.08842</td>\n",
       "      <td>0.04384</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.07399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>10.260</td>\n",
       "      <td>16.58</td>\n",
       "      <td>65.85</td>\n",
       "      <td>320.8</td>\n",
       "      <td>0.08877</td>\n",
       "      <td>0.08066</td>\n",
       "      <td>0.043580</td>\n",
       "      <td>0.024380</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.06714</td>\n",
       "      <td>...</td>\n",
       "      <td>22.04</td>\n",
       "      <td>71.08</td>\n",
       "      <td>357.4</td>\n",
       "      <td>0.14610</td>\n",
       "      <td>0.22460</td>\n",
       "      <td>0.17830</td>\n",
       "      <td>0.08333</td>\n",
       "      <td>0.2691</td>\n",
       "      <td>0.09479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>9.683</td>\n",
       "      <td>19.34</td>\n",
       "      <td>61.05</td>\n",
       "      <td>285.7</td>\n",
       "      <td>0.08491</td>\n",
       "      <td>0.05030</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.06235</td>\n",
       "      <td>...</td>\n",
       "      <td>25.59</td>\n",
       "      <td>69.10</td>\n",
       "      <td>364.2</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.09546</td>\n",
       "      <td>0.09350</td>\n",
       "      <td>0.03846</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>10.820</td>\n",
       "      <td>24.21</td>\n",
       "      <td>68.89</td>\n",
       "      <td>361.6</td>\n",
       "      <td>0.08192</td>\n",
       "      <td>0.06602</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.06328</td>\n",
       "      <td>...</td>\n",
       "      <td>31.45</td>\n",
       "      <td>83.90</td>\n",
       "      <td>505.6</td>\n",
       "      <td>0.12040</td>\n",
       "      <td>0.16330</td>\n",
       "      <td>0.06194</td>\n",
       "      <td>0.03264</td>\n",
       "      <td>0.3059</td>\n",
       "      <td>0.07626</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>10.860</td>\n",
       "      <td>21.48</td>\n",
       "      <td>68.51</td>\n",
       "      <td>360.5</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.04227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1661</td>\n",
       "      <td>0.05948</td>\n",
       "      <td>...</td>\n",
       "      <td>24.77</td>\n",
       "      <td>74.08</td>\n",
       "      <td>412.3</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.07348</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>11.130</td>\n",
       "      <td>22.44</td>\n",
       "      <td>71.49</td>\n",
       "      <td>378.4</td>\n",
       "      <td>0.09566</td>\n",
       "      <td>0.08194</td>\n",
       "      <td>0.048240</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.06552</td>\n",
       "      <td>...</td>\n",
       "      <td>28.26</td>\n",
       "      <td>77.80</td>\n",
       "      <td>436.6</td>\n",
       "      <td>0.10870</td>\n",
       "      <td>0.17820</td>\n",
       "      <td>0.15640</td>\n",
       "      <td>0.06413</td>\n",
       "      <td>0.3169</td>\n",
       "      <td>0.08032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>12.770</td>\n",
       "      <td>29.43</td>\n",
       "      <td>81.35</td>\n",
       "      <td>507.9</td>\n",
       "      <td>0.08276</td>\n",
       "      <td>0.04234</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.014990</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.05637</td>\n",
       "      <td>...</td>\n",
       "      <td>36.00</td>\n",
       "      <td>88.10</td>\n",
       "      <td>594.7</td>\n",
       "      <td>0.12340</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.08653</td>\n",
       "      <td>0.06498</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>0.06484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>9.333</td>\n",
       "      <td>21.94</td>\n",
       "      <td>59.01</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.09240</td>\n",
       "      <td>0.05605</td>\n",
       "      <td>0.039960</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>0.06576</td>\n",
       "      <td>...</td>\n",
       "      <td>25.05</td>\n",
       "      <td>62.86</td>\n",
       "      <td>295.8</td>\n",
       "      <td>0.11030</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.07993</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.2435</td>\n",
       "      <td>0.07393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>12.880</td>\n",
       "      <td>28.92</td>\n",
       "      <td>82.50</td>\n",
       "      <td>514.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.05824</td>\n",
       "      <td>0.061950</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.05708</td>\n",
       "      <td>...</td>\n",
       "      <td>35.74</td>\n",
       "      <td>88.84</td>\n",
       "      <td>595.7</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.16200</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.06493</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>0.07242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>10.290</td>\n",
       "      <td>27.61</td>\n",
       "      <td>65.67</td>\n",
       "      <td>321.4</td>\n",
       "      <td>0.09030</td>\n",
       "      <td>0.07658</td>\n",
       "      <td>0.059990</td>\n",
       "      <td>0.027380</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.06127</td>\n",
       "      <td>...</td>\n",
       "      <td>34.91</td>\n",
       "      <td>69.57</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.13840</td>\n",
       "      <td>0.17100</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.09127</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.08283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>10.160</td>\n",
       "      <td>19.59</td>\n",
       "      <td>64.73</td>\n",
       "      <td>311.7</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.07504</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.06331</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>67.88</td>\n",
       "      <td>347.3</td>\n",
       "      <td>0.12650</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.02232</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.06742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>9.423</td>\n",
       "      <td>27.88</td>\n",
       "      <td>59.26</td>\n",
       "      <td>271.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.04971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1742</td>\n",
       "      <td>0.06059</td>\n",
       "      <td>...</td>\n",
       "      <td>34.24</td>\n",
       "      <td>66.50</td>\n",
       "      <td>330.6</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.07158</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.06969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>14.590</td>\n",
       "      <td>22.68</td>\n",
       "      <td>96.39</td>\n",
       "      <td>657.1</td>\n",
       "      <td>0.08473</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.037360</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.06147</td>\n",
       "      <td>...</td>\n",
       "      <td>27.27</td>\n",
       "      <td>105.90</td>\n",
       "      <td>733.5</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.31710</td>\n",
       "      <td>0.36620</td>\n",
       "      <td>0.11050</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>0.08004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>11.510</td>\n",
       "      <td>23.93</td>\n",
       "      <td>74.52</td>\n",
       "      <td>403.5</td>\n",
       "      <td>0.09261</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.06570</td>\n",
       "      <td>...</td>\n",
       "      <td>37.16</td>\n",
       "      <td>82.28</td>\n",
       "      <td>474.2</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.25170</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.09653</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.08732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>14.050</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.044620</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>0.1537</td>\n",
       "      <td>0.06171</td>\n",
       "      <td>...</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.12410</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.13260</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>11.200</td>\n",
       "      <td>29.37</td>\n",
       "      <td>70.67</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.07449</td>\n",
       "      <td>0.03558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.05502</td>\n",
       "      <td>...</td>\n",
       "      <td>38.30</td>\n",
       "      <td>75.19</td>\n",
       "      <td>439.6</td>\n",
       "      <td>0.09267</td>\n",
       "      <td>0.05494</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.05905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>15.220</td>\n",
       "      <td>30.62</td>\n",
       "      <td>103.40</td>\n",
       "      <td>716.9</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.094290</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.07152</td>\n",
       "      <td>...</td>\n",
       "      <td>42.79</td>\n",
       "      <td>128.70</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.79170</td>\n",
       "      <td>1.17000</td>\n",
       "      <td>0.23560</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>0.14090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>20.920</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.06879</td>\n",
       "      <td>...</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.41860</td>\n",
       "      <td>0.65990</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.560</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.243900</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.600</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.092510</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.600</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.760</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1       2       3        4        5         6         7  \\\n",
       "0    17.990  10.38  122.80  1001.0  0.11840  0.27760  0.300100  0.147100   \n",
       "1    20.570  17.77  132.90  1326.0  0.08474  0.07864  0.086900  0.070170   \n",
       "2    19.690  21.25  130.00  1203.0  0.10960  0.15990  0.197400  0.127900   \n",
       "3    11.420  20.38   77.58   386.1  0.14250  0.28390  0.241400  0.105200   \n",
       "4    20.290  14.34  135.10  1297.0  0.10030  0.13280  0.198000  0.104300   \n",
       "5    12.450  15.70   82.57   477.1  0.12780  0.17000  0.157800  0.080890   \n",
       "6    18.250  19.98  119.60  1040.0  0.09463  0.10900  0.112700  0.074000   \n",
       "7    13.710  20.83   90.20   577.9  0.11890  0.16450  0.093660  0.059850   \n",
       "8    13.000  21.82   87.50   519.8  0.12730  0.19320  0.185900  0.093530   \n",
       "9    12.460  24.04   83.97   475.9  0.11860  0.23960  0.227300  0.085430   \n",
       "10   16.020  23.24  102.70   797.8  0.08206  0.06669  0.032990  0.033230   \n",
       "11   15.780  17.89  103.60   781.0  0.09710  0.12920  0.099540  0.066060   \n",
       "12   19.170  24.80  132.40  1123.0  0.09740  0.24580  0.206500  0.111800   \n",
       "13   15.850  23.95  103.70   782.7  0.08401  0.10020  0.099380  0.053640   \n",
       "14   13.730  22.61   93.60   578.3  0.11310  0.22930  0.212800  0.080250   \n",
       "15   14.540  27.54   96.73   658.8  0.11390  0.15950  0.163900  0.073640   \n",
       "16   14.680  20.13   94.74   684.5  0.09867  0.07200  0.073950  0.052590   \n",
       "17   16.130  20.68  108.10   798.8  0.11700  0.20220  0.172200  0.102800   \n",
       "18   19.810  22.15  130.00  1260.0  0.09831  0.10270  0.147900  0.094980   \n",
       "19   13.540  14.36   87.46   566.3  0.09779  0.08129  0.066640  0.047810   \n",
       "20   13.080  15.71   85.63   520.0  0.10750  0.12700  0.045680  0.031100   \n",
       "21    9.504  12.44   60.34   273.9  0.10240  0.06492  0.029560  0.020760   \n",
       "22   15.340  14.26  102.50   704.4  0.10730  0.21350  0.207700  0.097560   \n",
       "23   21.160  23.04  137.20  1404.0  0.09428  0.10220  0.109700  0.086320   \n",
       "24   16.650  21.38  110.00   904.6  0.11210  0.14570  0.152500  0.091700   \n",
       "25   17.140  16.40  116.00   912.7  0.11860  0.22760  0.222900  0.140100   \n",
       "26   14.580  21.53   97.41   644.8  0.10540  0.18680  0.142500  0.087830   \n",
       "27   18.610  20.25  122.10  1094.0  0.09440  0.10660  0.149000  0.077310   \n",
       "28   15.300  25.27  102.40   732.4  0.10820  0.16970  0.168300  0.087510   \n",
       "29   17.570  15.05  115.00   955.1  0.09847  0.11570  0.098750  0.079530   \n",
       "..      ...    ...     ...     ...      ...      ...       ...       ...   \n",
       "539   7.691  25.44   48.34   170.4  0.08668  0.11990  0.092520  0.013640   \n",
       "540  11.540  14.44   74.65   402.9  0.09984  0.11200  0.067370  0.025940   \n",
       "541  14.470  24.99   95.81   656.4  0.08837  0.12300  0.100900  0.038900   \n",
       "542  14.740  25.42   94.70   668.6  0.08275  0.07214  0.041050  0.030270   \n",
       "543  13.210  28.06   84.88   538.4  0.08671  0.06877  0.029870  0.032750   \n",
       "544  13.870  20.70   89.77   584.8  0.09578  0.10180  0.036880  0.023690   \n",
       "545  13.620  23.23   87.19   573.2  0.09246  0.06747  0.029740  0.024430   \n",
       "546  10.320  16.35   65.31   324.9  0.09434  0.04994  0.010120  0.005495   \n",
       "547  10.260  16.58   65.85   320.8  0.08877  0.08066  0.043580  0.024380   \n",
       "548   9.683  19.34   61.05   285.7  0.08491  0.05030  0.023370  0.009615   \n",
       "549  10.820  24.21   68.89   361.6  0.08192  0.06602  0.015480  0.008160   \n",
       "550  10.860  21.48   68.51   360.5  0.07431  0.04227  0.000000  0.000000   \n",
       "551  11.130  22.44   71.49   378.4  0.09566  0.08194  0.048240  0.022570   \n",
       "552  12.770  29.43   81.35   507.9  0.08276  0.04234  0.019970  0.014990   \n",
       "553   9.333  21.94   59.01   264.0  0.09240  0.05605  0.039960  0.012820   \n",
       "554  12.880  28.92   82.50   514.3  0.08123  0.05824  0.061950  0.023430   \n",
       "555  10.290  27.61   65.67   321.4  0.09030  0.07658  0.059990  0.027380   \n",
       "556  10.160  19.59   64.73   311.7  0.10030  0.07504  0.005025  0.011160   \n",
       "557   9.423  27.88   59.26   271.3  0.08123  0.04971  0.000000  0.000000   \n",
       "558  14.590  22.68   96.39   657.1  0.08473  0.13300  0.102900  0.037360   \n",
       "559  11.510  23.93   74.52   403.5  0.09261  0.10210  0.111200  0.041050   \n",
       "560  14.050  27.15   91.38   600.4  0.09929  0.11260  0.044620  0.043040   \n",
       "561  11.200  29.37   70.67   386.0  0.07449  0.03558  0.000000  0.000000   \n",
       "562  15.220  30.62  103.40   716.9  0.10480  0.20870  0.255000  0.094290   \n",
       "563  20.920  25.09  143.00  1347.0  0.10990  0.22360  0.317400  0.147400   \n",
       "564  21.560  22.39  142.00  1479.0  0.11100  0.11590  0.243900  0.138900   \n",
       "565  20.130  28.25  131.20  1261.0  0.09780  0.10340  0.144000  0.097910   \n",
       "566  16.600  28.08  108.30   858.1  0.08455  0.10230  0.092510  0.053020   \n",
       "567  20.600  29.33  140.10  1265.0  0.11780  0.27700  0.351400  0.152000   \n",
       "568   7.760  24.54   47.92   181.0  0.05263  0.04362  0.000000  0.000000   \n",
       "\n",
       "          8        9    ...         21      22      23       24       25  \\\n",
       "0    0.2419  0.07871    ...      17.33  184.60  2019.0  0.16220  0.66560   \n",
       "1    0.1812  0.05667    ...      23.41  158.80  1956.0  0.12380  0.18660   \n",
       "2    0.2069  0.05999    ...      25.53  152.50  1709.0  0.14440  0.42450   \n",
       "3    0.2597  0.09744    ...      26.50   98.87   567.7  0.20980  0.86630   \n",
       "4    0.1809  0.05883    ...      16.67  152.20  1575.0  0.13740  0.20500   \n",
       "5    0.2087  0.07613    ...      23.75  103.40   741.6  0.17910  0.52490   \n",
       "6    0.1794  0.05742    ...      27.66  153.20  1606.0  0.14420  0.25760   \n",
       "7    0.2196  0.07451    ...      28.14  110.60   897.0  0.16540  0.36820   \n",
       "8    0.2350  0.07389    ...      30.73  106.20   739.3  0.17030  0.54010   \n",
       "9    0.2030  0.08243    ...      40.68   97.65   711.4  0.18530  1.05800   \n",
       "10   0.1528  0.05697    ...      33.88  123.80  1150.0  0.11810  0.15510   \n",
       "11   0.1842  0.06082    ...      27.28  136.50  1299.0  0.13960  0.56090   \n",
       "12   0.2397  0.07800    ...      29.94  151.70  1332.0  0.10370  0.39030   \n",
       "13   0.1847  0.05338    ...      27.66  112.00   876.5  0.11310  0.19240   \n",
       "14   0.2069  0.07682    ...      32.01  108.80   697.7  0.16510  0.77250   \n",
       "15   0.2303  0.07077    ...      37.13  124.10   943.2  0.16780  0.65770   \n",
       "16   0.1586  0.05922    ...      30.88  123.40  1138.0  0.14640  0.18710   \n",
       "17   0.2164  0.07356    ...      31.48  136.80  1315.0  0.17890  0.42330   \n",
       "18   0.1582  0.05395    ...      30.88  186.80  2398.0  0.15120  0.31500   \n",
       "19   0.1885  0.05766    ...      19.26   99.70   711.2  0.14400  0.17730   \n",
       "20   0.1967  0.06811    ...      20.49   96.09   630.5  0.13120  0.27760   \n",
       "21   0.1815  0.06905    ...      15.66   65.13   314.9  0.13240  0.11480   \n",
       "22   0.2521  0.07032    ...      19.08  125.10   980.9  0.13900  0.59540   \n",
       "23   0.1769  0.05278    ...      35.59  188.00  2615.0  0.14010  0.26000   \n",
       "24   0.1995  0.06330    ...      31.56  177.00  2215.0  0.18050  0.35780   \n",
       "25   0.3040  0.07413    ...      21.40  152.40  1461.0  0.15450  0.39490   \n",
       "26   0.2252  0.06924    ...      33.21  122.40   896.9  0.15250  0.66430   \n",
       "27   0.1697  0.05699    ...      27.26  139.90  1403.0  0.13380  0.21170   \n",
       "28   0.1926  0.06540    ...      36.71  149.30  1269.0  0.16410  0.61100   \n",
       "29   0.1739  0.06149    ...      19.52  134.90  1227.0  0.12550  0.28120   \n",
       "..      ...      ...    ...        ...     ...     ...      ...      ...   \n",
       "539  0.2037  0.07751    ...      31.89   54.49   223.6  0.15960  0.30640   \n",
       "540  0.1818  0.06782    ...      19.68   78.78   457.8  0.13450  0.21180   \n",
       "541  0.1872  0.06341    ...      31.73  113.50   808.9  0.13400  0.42020   \n",
       "542  0.1840  0.05680    ...      32.29  107.40   826.4  0.10600  0.13760   \n",
       "543  0.1628  0.05781    ...      37.17   92.48   629.6  0.10720  0.13810   \n",
       "544  0.1620  0.06688    ...      24.75   99.17   688.6  0.12640  0.20370   \n",
       "545  0.1664  0.05801    ...      29.09   97.58   729.8  0.12160  0.15170   \n",
       "546  0.1885  0.06201    ...      21.77   71.12   384.9  0.12850  0.08842   \n",
       "547  0.1669  0.06714    ...      22.04   71.08   357.4  0.14610  0.22460   \n",
       "548  0.1580  0.06235    ...      25.59   69.10   364.2  0.11990  0.09546   \n",
       "549  0.1976  0.06328    ...      31.45   83.90   505.6  0.12040  0.16330   \n",
       "550  0.1661  0.05948    ...      24.77   74.08   412.3  0.10010  0.07348   \n",
       "551  0.2030  0.06552    ...      28.26   77.80   436.6  0.10870  0.17820   \n",
       "552  0.1539  0.05637    ...      36.00   88.10   594.7  0.12340  0.10640   \n",
       "553  0.1692  0.06576    ...      25.05   62.86   295.8  0.11030  0.08298   \n",
       "554  0.1566  0.05708    ...      35.74   88.84   595.7  0.12270  0.16200   \n",
       "555  0.1593  0.06127    ...      34.91   69.57   357.6  0.13840  0.17100   \n",
       "556  0.1791  0.06331    ...      22.88   67.88   347.3  0.12650  0.12000   \n",
       "557  0.1742  0.06059    ...      34.24   66.50   330.6  0.10730  0.07158   \n",
       "558  0.1454  0.06147    ...      27.27  105.90   733.5  0.10260  0.31710   \n",
       "559  0.1388  0.06570    ...      37.16   82.28   474.2  0.12980  0.25170   \n",
       "560  0.1537  0.06171    ...      33.17  100.20   706.7  0.12410  0.22640   \n",
       "561  0.1060  0.05502    ...      38.30   75.19   439.6  0.09267  0.05494   \n",
       "562  0.2128  0.07152    ...      42.79  128.70   915.0  0.14170  0.79170   \n",
       "563  0.2149  0.06879    ...      29.41  179.10  1819.0  0.14070  0.41860   \n",
       "564  0.1726  0.05623    ...      26.40  166.10  2027.0  0.14100  0.21130   \n",
       "565  0.1752  0.05533    ...      38.25  155.00  1731.0  0.11660  0.19220   \n",
       "566  0.1590  0.05648    ...      34.12  126.70  1124.0  0.11390  0.30940   \n",
       "567  0.2397  0.07016    ...      39.42  184.60  1821.0  0.16500  0.86810   \n",
       "568  0.1587  0.05884    ...      30.37   59.16   268.6  0.08996  0.06444   \n",
       "\n",
       "          26       27      28       29  diagnosis  \n",
       "0    0.71190  0.26540  0.4601  0.11890          0  \n",
       "1    0.24160  0.18600  0.2750  0.08902          0  \n",
       "2    0.45040  0.24300  0.3613  0.08758          0  \n",
       "3    0.68690  0.25750  0.6638  0.17300          0  \n",
       "4    0.40000  0.16250  0.2364  0.07678          0  \n",
       "5    0.53550  0.17410  0.3985  0.12440          0  \n",
       "6    0.37840  0.19320  0.3063  0.08368          0  \n",
       "7    0.26780  0.15560  0.3196  0.11510          0  \n",
       "8    0.53900  0.20600  0.4378  0.10720          0  \n",
       "9    1.10500  0.22100  0.4366  0.20750          0  \n",
       "10   0.14590  0.09975  0.2948  0.08452          0  \n",
       "11   0.39650  0.18100  0.3792  0.10480          0  \n",
       "12   0.36390  0.17670  0.3176  0.10230          0  \n",
       "13   0.23220  0.11190  0.2809  0.06287          0  \n",
       "14   0.69430  0.22080  0.3596  0.14310          0  \n",
       "15   0.70260  0.17120  0.4218  0.13410          0  \n",
       "16   0.29140  0.16090  0.3029  0.08216          0  \n",
       "17   0.47840  0.20730  0.3706  0.11420          0  \n",
       "18   0.53720  0.23880  0.2768  0.07615          0  \n",
       "19   0.23900  0.12880  0.2977  0.07259          1  \n",
       "20   0.18900  0.07283  0.3184  0.08183          1  \n",
       "21   0.08867  0.06227  0.2450  0.07773          1  \n",
       "22   0.63050  0.23930  0.4667  0.09946          0  \n",
       "23   0.31550  0.20090  0.2822  0.07526          0  \n",
       "24   0.46950  0.20950  0.3613  0.09564          0  \n",
       "25   0.38530  0.25500  0.4066  0.10590          0  \n",
       "26   0.55390  0.27010  0.4264  0.12750          0  \n",
       "27   0.34460  0.14900  0.2341  0.07421          0  \n",
       "28   0.63350  0.20240  0.4027  0.09876          0  \n",
       "29   0.24890  0.14560  0.2756  0.07919          0  \n",
       "..       ...      ...     ...      ...        ...  \n",
       "539  0.33930  0.05000  0.2790  0.10660          1  \n",
       "540  0.17970  0.06918  0.2329  0.08134          1  \n",
       "541  0.40400  0.12050  0.3187  0.10230          1  \n",
       "542  0.16110  0.10950  0.2722  0.06956          1  \n",
       "543  0.10620  0.07958  0.2473  0.06443          1  \n",
       "544  0.13770  0.06845  0.2249  0.08492          1  \n",
       "545  0.10490  0.07174  0.2642  0.06953          1  \n",
       "546  0.04384  0.02381  0.2681  0.07399          1  \n",
       "547  0.17830  0.08333  0.2691  0.09479          1  \n",
       "548  0.09350  0.03846  0.2552  0.07920          1  \n",
       "549  0.06194  0.03264  0.3059  0.07626          1  \n",
       "550  0.00000  0.00000  0.2458  0.06592          1  \n",
       "551  0.15640  0.06413  0.3169  0.08032          1  \n",
       "552  0.08653  0.06498  0.2407  0.06484          1  \n",
       "553  0.07993  0.02564  0.2435  0.07393          1  \n",
       "554  0.24390  0.06493  0.2372  0.07242          1  \n",
       "555  0.20000  0.09127  0.2226  0.08283          1  \n",
       "556  0.01005  0.02232  0.2262  0.06742          1  \n",
       "557  0.00000  0.00000  0.2475  0.06969          1  \n",
       "558  0.36620  0.11050  0.2258  0.08004          1  \n",
       "559  0.36300  0.09653  0.2112  0.08732          1  \n",
       "560  0.13260  0.10480  0.2250  0.08321          1  \n",
       "561  0.00000  0.00000  0.1566  0.05905          1  \n",
       "562  1.17000  0.23560  0.4089  0.14090          0  \n",
       "563  0.65990  0.25420  0.2929  0.09873          0  \n",
       "564  0.41070  0.22160  0.2060  0.07115          0  \n",
       "565  0.32150  0.16280  0.2572  0.06637          0  \n",
       "566  0.34030  0.14180  0.2218  0.07820          0  \n",
       "567  0.93870  0.26500  0.4087  0.12400          0  \n",
       "568  0.00000  0.00000  0.2871  0.07039          1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from funcoes import readDataset\n",
    "from constantes import *\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "data = datasets.load_breast_cancer() #readDataset('id')\n",
    "x = data.x\n",
    "y = data.target\n",
    "featuresnames=\n",
    "cancerDeMamaDF = pd.DataFrame(x)\n",
    "cancerDeMamaDF[CLASSE] = y\n",
    "cancerDeMamaDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse dataset não apresenta valores faltantes ou inválidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancerDeMamaDF.groupby(CLASSE).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo da informação mútua de cada atributo em relação à classe alvo\n",
    "\n",
    "Para verificar quais atributos mais influenciam a classe alvo realizamos o cálculo de entropia para cada atributo.  A entropia é uma métrica de mede a desorganização dos dados. A informação mútua, por sua vez, mede a correlação entre os dados, e utiliza da entropia em seu cálculo. Quanto maior o valor da entropia, maior a desorganização dos dados dos conjuntos comparados, e portanto, menor a correlação entre eles.\n",
    "\n",
    "Aplicado ao problema deste trabalho verificaremos a informação mútua para determinar quais atributos são mais correlatos a classe alvo. Como explicado anteriormente, a informação mútua é inversamente proporcional à correlação, ou seja, os atributos mais relacionados à classe alvo são aqueles com informação mútua mais baixa.\n",
    "\n",
    "A tabela abaixo mostra o resultado do experimento, em ordem crescente, sendo que as informações mútuas dos atributos variam entre 0 e 0.402583. Os cinco atributos mais influentes segundo essa métrica são texture_se,\tfractal_dimension_mean, smoothness_se, symmetry_se e fractal_dimension_se."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    |   texture_se |   fractal_dimension_mean |   smoothness_se |   symmetry_se |   fractal_dimension_se |   symmetry_mean |   fractal_dimension_worst |   compactness_se |   smoothness_mean |   smoothness_worst |   symmetry_worst |   texture_mean |   concavity_se |   texture_worst |   concave points_se |   compactness_mean |   compactness_worst |   radius_se |   perimeter_se |   concavity_worst |   area_se |   area_mean |   radius_mean |   concavity_mean |   perimeter_mean |   concave points_worst |   concave points_mean |   radius_worst |   area_worst |   perimeter_worst |\n",
    "|---:|-------------:|-------------------------:|----------------:|--------------:|-----------------------:|----------------:|--------------------------:|-----------------:|------------------:|-------------------:|-----------------:|---------------:|---------------:|----------------:|--------------------:|-------------------:|--------------------:|------------:|---------------:|------------------:|----------:|------------:|--------------:|-----------------:|-----------------:|-----------------------:|----------------------:|---------------:|-------------:|------------------:|\n",
    "|  0 |            0 |               0.00458106 |       0.0149844 |     0.0152172 |              0.0390889 |       0.0648613 |                 0.0682045 |        0.0771953 |         0.0827246 |          0.0951973 |        0.0960381 |       0.103002 |        0.11473 |        0.120734 |            0.129724 |           0.210436 |            0.225538 |    0.247466 |       0.273684 |          0.315299 |  0.338695 |    0.359295 |      0.366089 |         0.372899 |         0.402786 |               0.438696 |              0.441732 |       0.457661 |     0.463796 |          0.474398 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando o impacto da remoção de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada cédula mostra as imagem que foram geradas e comparadas em conjuto. A cédula abaixo contém a árvore de decisão sem remoção de atributos, ela foi mantida nas comparações\n",
    "\n",
    "Foi utilizada a árvore de decisão com o parametro min_samples_split = 0.0002, porque a mesma apresentou o melhor resultado com relação min_samples_split = 0.25 e min_samples_split = 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusões\n",
    "\n",
    "Não houve diferenças nas árvores de decisões ao remover:\n",
    "- concavity_mean e concave points_mean\n",
    "- area_mean e perimeter_mean\n",
    "- perimeter_se e perimeter_se\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento de comparação entre duas representações da base pelo melhor método de árvore de decisão identificado via gridsearch\n",
    "\n",
    "Foram definidas duas representações: a primeira com todos os atributos e a segunda excluídos alguns atributos. O objetivo deste experimento é verificar se a remoção desses atributos impacta o resultado, e caso não haja impacto, pode-se reduzir a dimensão da base para criação de modelos futuros.\n",
    "\n",
    "Os atributos removidos foram concavity_mean, concave points_mean, area_mean, perimeter_mean, perimeter_se, perimeter_se. Eles foram selecionados por serem correlationados com outros atributos do dataset.\n",
    "\n",
    "Para a representação de todos os atributos obtivemos como min_sample_split = 0.25, e para a representação excluídos alguns atributos min_sample_split = 0.0002.\n",
    "\n",
    " Com todos os atributos\n",
    "best parameters: \n",
    "{'min_samples_split': 0.25, 'random_state': 1}\n",
    "\n",
    "classification_report:\n",
    "\n",
    "|              |   precision |   recall |   f1-score |   support |\n",
    "|:-------------|------------:|---------:|-----------:|----------:|\n",
    "| B            |        0.96 |     0.99 |       0.97 |        67 |\n",
    "| M            |        0.98 |     0.94 |       0.96 |        47 |\n",
    "| accuracy     |        0.96 |     0.96 |       0.96 |       114 |\n",
    "| macro avg    |        0.97 |     0.96 |       0.96 |       114 |\n",
    "| weighted avg |        0.97 |     0.96 |       0.96 |       114 |\n",
    "\n",
    "confusion matrix:\n",
    "\n",
    "|        |   B_pred |   M_pred |\n",
    "|:-------|---------:|---------:|\n",
    "| B_true |       66 |        1 |\n",
    "| M_true |        3 |       44 |\n",
    "\n",
    "Sem alguns atributos\n",
    "best parameters: \n",
    "{'min_samples_split': 0.0002, 'random_state': 1}\n",
    "\n",
    "classification_report:\n",
    "\n",
    "|              |   precision |   recall |   f1-score |   support |\n",
    "|:-------------|------------:|---------:|-----------:|----------:|\n",
    "| B            |        0.97 |     0.93 |       0.95 |        67 |\n",
    "| M            |        0.9  |     0.96 |       0.93 |        47 |\n",
    "| accuracy     |        0.94 |     0.94 |       0.94 |       114 |\n",
    "| macro avg    |        0.93 |     0.94 |       0.94 |       114 |\n",
    "| weighted avg |        0.94 |     0.94 |       0.94 |       114 |\n",
    "\n",
    "confusion matrix:\n",
    "\n",
    "|        |   B_pred |   M_pred |\n",
    "|:-------|---------:|---------:|\n",
    "| B_true |       62 |        5 |\n",
    "| M_true |        2 |       45 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrando os melhores parâmetros para SVM via grid search\n",
    "O dataset foi dividido em 80% treino e 20% teste, sendo o dataset de treino utilizado para encontrar os melhores parâmetros e o dataset de testes para validar o modelo considerado o melhor <img src=\"img/cv-gridsearch.jpeg\" alt=\"Esquema de divisão do dataset para encontrar os melhores parâmetros e testar o melhor método encontrado\">\n",
    "\n",
    "Para encontrar os melhores parâmetros do método SVM para o dataset foi feita uma _grid search_ utilizando _cross validation_ do tipo K-fold para k = 5. As configurações testadas foram combinações dos parâmetros kernel = {linear, rbf} e C = {1, 10, 100, 1000}. O melhor resultado foi o classificador SVM de C = 1 e kernel linear.\n",
    "\n",
    "Encontrado o melhor modelo foi feito o teste com dados não vistos anteriormente.\n",
    "\n",
    "## Avaliação do método\n",
    "\n",
    "Para o melhor modelo encontrado obtivemos os seguintes resultados:\n",
    "\n",
    "\n",
    "|              |   precision |   recall |   f1-score |   support |\n",
    "|:-------------|------------:|---------:|-----------:|----------:|\n",
    "| B            |        0.98 |     0.94 |       0.96 |        67 |\n",
    "| M            |        0.92 |     0.98 |       0.95 |        47 |\n",
    "| accuracy     |        0.96 |     0.96 |       0.96 |       114 |\n",
    "| macro avg    |        0.95 |     0.96 |       0.96 |       114 |\n",
    "| weighted avg |        0.96 |     0.96 |       0.96 |       114 |\n",
    "\n",
    "<p style=\"text-align: center;\"> Precision, Recall, F1-score e Support por classe </p>\n",
    "\n",
    "|        |   B_pred |   M_pred |\n",
    "|:-------|---------:|---------:|\n",
    "| B_true |       63 |        4 |\n",
    "| M_true |        1 |       46 |\n",
    "\n",
    "<p style=\"text-align: center;\"> Matrix de confusão </p>\n",
    "\n",
    "Os resultados acima mostram que a métrica precisão é mais alta para predizer os tumores do tipo benigno enquanto a métrica revocação é mais alta para os tumores malignos. Estes resultados são satisfatórios, pois indicam que dos tumores malignos, 98% foram preditos corretamente, sendo que do que foi predito como maligno 92% era de fato maligno. É um modelo que erra mais indicando que um tumor benigno é maligno do que ao contrário, o que cumpre o papel mais importante de detectar corretamente os tumores malignos. Abaixo a matriz de confusão que confirma as conclusões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação de métodos via gridsearch\n",
    "Foram comparados 4 modelos com variação de parâmetros:\n",
    "- **SVM Linear**: Variação do custo: $2^{-1}, 2^1,2^3,2^5$\n",
    "- **SVM RBF**: Variação do custo: $2^{-1}, 2^1,2^3$ e, para cada variação do custo, você deverá variar o Gama: $2^{-1}, 2^1,2^3$\n",
    "- **KNN**: Variação do k: $2^2,2^4,2^6,2^8$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    | estimator              |   mean_fit_time |   std_fit_time |   mean_score_time |   std_score_time | params                                           |   split0_test_score |   split1_test_score |   split2_test_score |   split3_test_score |   split4_test_score |   split5_test_score |   split6_test_score |   split7_test_score |   split8_test_score |   split9_test_score |   mean_test_score |   std_test_score |\n",
    "|---:|:-----------------------|----------------:|---------------:|------------------:|-----------------:|:-------------------------------------------------|--------------------:|--------------------:|--------------------:|--------------------:|--------------------:|--------------------:|--------------------:|--------------------:|--------------------:|--------------------:|------------------:|-----------------:|\n",
    "|  0 | KNeighborsClassifier   |      0.00190814 |    0.000330102 |        0.00350664 |      5.32728e-05 | {'n_neighbors': 16}                              |            0.835443 |            0.904762 |            0.904762 |            0.90566  |            0.981818 |            0.956522 |            0.903226 |            0.923077 |            0.827586 |            0.96     |          0.910198 |        0.0473906 |\n",
    "|  1 | DecisionTreeClassifier |      0.00924771 |    0.001484    |        0.00210447 |      0.000634988 | {'min_samples_split': 0.0002, 'random_state': 1} |            0.966292 |            0.883721 |            0.878049 |            0.90566  |            0.945455 |            0.956522 |            0.857143 |            0.962963 |            0.896552 |            0.774194 |          0.902881 |        0.0563647 |\n",
    "|  2 | KNeighborsClassifier   |      0.00227652 |    0.000855482 |        0.00368242 |      0.000412773 | {'n_neighbors': 4}                               |            0.835443 |            0.878049 |            0.9      |            0.846154 |            0.962963 |            0.869565 |            0.903226 |            0.916667 |            0.827586 |            0.916667 |          0.885577 |        0.0402446 |\n",
    "|  3 | LinearSVC              |      0.0406918  |    0.00366272  |        0.00190208 |      0.000393019 | {'C': 2}                                         |            0.930233 |            0.785714 |            0.95     |            0.884615 |            0.981818 |            0.909091 |            0.83871  |            0.96     |            0.782609 |            0.818182 |          0.884213 |        0.0698573 |\n",
    "|  4 | DecisionTreeClassifier |      0.00735047 |    0.000476387 |        0.00136442 |      4.49518e-05 | {'min_samples_split': 0.25, 'random_state': 1}   |            0.864198 |            0.857143 |            0.878049 |            0.90566  |            0.964286 |            0.956522 |            0.823529 |            0.923077 |            0.742857 |            0.88     |          0.879531 |        0.0618965 |\n",
    "|  5 | LinearSVC              |      0.0389403  |    0.00321161  |        0.00213311 |      0.000472816 | {'C': 8}                                         |            0.930233 |            0.878049 |            0.923077 |            0.833333 |            0.823529 |            0.8      |            0.896552 |            0.916667 |            0.8      |            0.96     |          0.875997 |        0.0550898 |\n",
    "|  6 | KNeighborsClassifier   |      0.0019573  |    0.000429762 |        0.00399561 |      0.000105574 | {'n_neighbors': 64}                              |            0.773333 |            0.777778 |            0.878049 |            0.862745 |            0.943396 |            0.956522 |            0.903226 |            0.88     |            0.814815 |            0.96     |          0.874837 |        0.0654895 |\n",
    "|  7 | DecisionTreeClassifier |      0.00643585 |    0.000636762 |        0.00144951 |      0.000167366 | {'min_samples_split': 0.5, 'random_state': 1}    |            0.917647 |            0.857143 |            0.863636 |            0.949153 |            0.964286 |            0.88     |            0.833333 |            0.866667 |            0.742857 |            0.827586 |          0.870306 |        0.0608961 |\n",
    "|  8 | LinearSVC              |      0.0375731  |    0.00200736  |        0.00176952 |      0.000293902 | {'C': 32}                                        |            0.864198 |            0.878049 |            0.711864 |            0.884615 |            0.923077 |            0.846154 |            0.896552 |            0.888889 |            0.787879 |            0.8      |          0.848212 |        0.0605392 |\n",
    "|  9 | LinearSVC              |      0.0369243  |    0.00171693  |        0.00207772 |      0.000878731 | {'C': 0.5}                                       |            0.878049 |            0.878049 |            0.904762 |            0.885246 |            0.965517 |            0.733333 |            0.83871  |            0.96     |            0.833333 |            0.577778 |          0.845948 |        0.108685  |\n",
    "| 10 | KNeighborsClassifier   |      0.0015486  |    6.02027e-05 |        0.00681918 |      0.00650293  | {'n_neighbors': 256}                             |            0.647059 |            0.666667 |            0.833333 |            0.634146 |            0.88     |            0.857143 |            0.857143 |            0.869565 |            0.782609 |            0.869565 |          0.789583 |        0.0957558 |\n",
    "| 11 | SVC                    |      0.0190641  |    0.00276822  |        0.00357368 |      0.000754005 | {'C': 0.5, 'gamma': 2}                           |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |          0        |        0         |\n",
    "| 12 | SVC                    |      0.0197334  |    0.00212728  |        0.0039005  |      0.000659666 | {'C': 8, 'gamma': 8}                             |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |          0        |        0         |\n",
    "| 13 | SVC                    |      0.0225755  |    0.00433221  |        0.00356915 |      0.000739413 | {'C': 8, 'gamma': 2}                             |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |          0        |        0         |\n",
    "| 14 | SVC                    |      0.0193894  |    0.00116017  |        0.00341363 |      0.000622103 | {'C': 8, 'gamma': 0.5}                           |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |          0        |        0         |\n",
    "| 15 | SVC                    |      0.0228866  |    0.00356499  |        0.00409553 |      0.000975325 | {'C': 2, 'gamma': 8}                             |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |          0        |        0         |\n",
    "| 16 | SVC                    |      0.0211589  |    0.00504687  |        0.00413313 |      0.00111245  | {'C': 2, 'gamma': 2}                             |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |          0        |        0         |\n",
    "| 17 | SVC                    |      0.0192814  |    0.00193296  |        0.00333257 |      0.000450019 | {'C': 2, 'gamma': 0.5}                           |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |          0        |        0         |\n",
    "| 18 | SVC                    |      0.0172114  |    0.00106274  |        0.00344226 |      0.000791226 | {'C': 0.5, 'gamma': 8}                           |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |          0        |        0         |\n",
    "| 19 | SVC                    |      0.0177542  |    0.00115865  |        0.00339539 |      0.000821195 | {'C': 0.5, 'gamma': 0.5}                         |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |            0        |          0        |        0         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
