{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção automática de câncer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualização\n",
    "\n",
    "O câncer de mama é o de maior incidência em mulheres do Brasil. De acordo com o INCA (Instituto Nacional de Câncer) em 2017 de todas as neoplasias que levaram a óbito em mulheres, 16,1%  foram com localização primária na mama. Em 2018 esse número subiu para 29,5%, mostrando como esse é um problema que possui uma curva ascendente. Para diagnósticos precoces a chance de cura é alta chegando até 95%.\n",
    "\n",
    "Para a investigação, além do exame clínico das mamas, exames de imagem podem ser recomendados, como mamografia, ultrassonografia ou ressonância magnética. A confirmação diagnóstica só é feita, porém, por meio da biópsia, sendo necessária a retirada de um fragmento do nódulo em uma pequena cirurgia. \n",
    "\n",
    "Como qualquer cirurgia, existem o risco da operação. Dessa forma, um meio de diagnosticar de forma menos agressiva se o nódulo é maligno ou benigno seria analisando suas características, verificando os valores encontrados nos exames prévios. Além disso, o processo de diagnóstico seria muito mais rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem\n",
    "\n",
    "A base de dados utilizada nesse trabalho foi obtida no [Kaggle](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data). Essa base é consiste em um conjunto de instâncias compostas por atributos númericos e classe alvo. A partir dessas instâncias serão criados e avaliados modelos para detecção automática de câncer, ou seja, prever se um nódulo é maligno ou benigno. Os atributos e a classe alvo são:\n",
    "\n",
    "### Atributos: \n",
    "* id: identificador\n",
    "* radius_mean: distância média do ponto central até o perimetro\n",
    "* texture_mean: desvio padrão dos valores da escala de cinza\n",
    "* perimeter_mean: tamanho médio do tumor central\n",
    "* area_mean: área média do tumor\n",
    "* smoothness_mean: média da varição dos comprimentos de raio\n",
    "* compactness_mean: perimeter_mean^2 / area_mean - 1.0\n",
    "* concavity_mean: média de gravidade de porções côncavas do contorno\n",
    "* concave points_mean: média do número de gravidade de porções côncavas do contorno\n",
    "* symmetry_mean: média de simetria\n",
    "* fractal_dimension_mean: média para \"aproximação do contorno\" - 1\n",
    "* radius_se: erro para radius_mean\n",
    "* texture_ses: erro para texture_mean\n",
    "* perimeter_se: perimetro\n",
    "* area_se: erro área\n",
    "* smoothness_se: error para smoothness_mean\n",
    "* compactness_se: error para compactness_mean\n",
    "* concavity_se: erro para concavity_mean\n",
    "* concave points_se: erro para concave points_mean\n",
    "* symmetry_se:  erra para simetria\n",
    "* fractal_dimension_se: erro para fractal_dimension_mean\n",
    "* radius_worst: média dos três maiores valores do raio\n",
    "* texture_worst: média dos três maiores valores de texture_mean\n",
    "* area_worst: média dos três maiores valores de área\n",
    "* smoothness_worst: média dos três maiores valores de smoothness_mean\n",
    "* compactness_worst: média dos três maiores valores de compactness_mean\n",
    "* concavity_worst: média dos três maiores valores de concave points_mean\n",
    "* concave points_worst: média dos três maiores valores de concavity_mean\n",
    "* fractal_dimension_worst: média dos três maiores valores de fractal_dimension_mean\n",
    "\n",
    "### Classe\n",
    "* diagnosis: O diagnóstico dos tecidos mamários(M = maligno, B = benigno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalhos Relacionados\n",
    "\n",
    "### Applications of Machine Learning in Cancer Prediction and Prognosis\n",
    "\n",
    "Em 2006, Joseph A. Cruz escreveu um artigo com um estudo sobre as aplicações de aprendizado de máquina na previsão e prognóstico do câncer. Foi realizada uma ampla pesquisa sobre os diferentes tipos de métodos de aprendizado de máquina que estão sendo usados, os tipos de dados que estão sendo integrados e o desempenho desses métodos na previsão e prognóstico do câncer.\n",
    "\n",
    "Foram comparados árvore de decisão, naive bayes, KNN, redes neurais, SVM e algoritmos genéticos, considerando vários estudos de caso. \n",
    "\n",
    "Um dos problemas mais comuns observados entre os estudos pesquisados foram a falta de atenção ao tamanho dos dados e validação. Isso mostra como é importante ter um conjunto de dados suficientemente grande que possa ser particionado em conjuntos de treinamento e teste disjuntos ou submetido a alguma forma razoável de n-fold cross-validation para conjuntos de dados menores.\n",
    "\n",
    "Foi mostrado uma tabela com os métodos de aprendizado de máquina usados na previsão de câncer, mostrando os tipos de câncer, parâmetros clínicos, escolha do algoritmo, desempenho e tipo de dados de treinamento.\n",
    "\n",
    "O artigo conclui dizendo como as redes neurais ainda são predominantes mas uma variedade crescente de estratégias alternativas de aprendizado de máquina estão sendo utilizadas e sendo aplicadas a muitos tipos de câncer.\n",
    "\n",
    "### An expert system for detection of breast cancer based on association rules and neural network\n",
    "\n",
    "Murat Karabatak escreveu um artigo em 2009 apresentando um sistema especialista para detecção de câncer de mama com base em regras de associação (AR) e rede neural (NN). Nesse estudo as AR são utilizadas para reduzir a dimensão da base de dados enquanto a rede neural é utilizada na classificação. \n",
    "\n",
    "São utilizados duas técnicas diferentes de AR para eliminar entradas desnecessárias. A técnica AR1 usa todos os parâmetros de entrada e todos os seus registros para encontrar relações entre eles. Se forem encontradas regras que tenham valor de suporte suficiente e alto valor de confiança, é possível eliminar algumas entradas. Já o AR2 usa todos os parâmetros de entrada, mas nem todos os seus registros.\n",
    "\n",
    "Para a rede neural é utilizado um multi-layer perceptron, sendo sua entrada as features obtidas pela AR.\n",
    "\n",
    "Foram realizados testes com NN, NN + AR1 e NN + AR2, e os resultados obtidos foram:\n",
    "\n",
    "| Classificador | Épocas | Classificações Corretas | Classificações erradas | Taxa de classificação correta |\n",
    "|---------------|--------|-------------------------|------------------------|-------------------------------|\n",
    "|      NN       |   61   |           216           |           11           |              95,2             |\n",
    "|    AR1 + NN   |   44   |           221           |            6           |              97,4             |\n",
    "|    AR2 + NN   |   33   |           217           |           10           |              95,6             |\n",
    "\n",
    "Os melhores resultados foram obtidos com AR1 + NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcoes import readDataset\n",
    "from constantes import *\n",
    "from experiments import Experiments\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  diagnosis  \n",
       "0          0.4601                  0.11890          0  \n",
       "1          0.2750                  0.08902          0  \n",
       "2          0.3613                  0.08758          0  \n",
       "3          0.6638                  0.17300          0  \n",
       "4          0.2364                  0.07678          0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancerDeMamaDF = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "cancerDeMamaDF[CLASSE] = data.target\n",
    "cancerDeMamaDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse dataset não apresenta valores faltantes ou inválidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">mean radius</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean texture</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">worst symmetry</th>\n",
       "      <th colspan=\"8\" halign=\"left\">worst fractal dimension</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212.0</td>\n",
       "      <td>17.462830</td>\n",
       "      <td>3.203971</td>\n",
       "      <td>10.950</td>\n",
       "      <td>15.075</td>\n",
       "      <td>17.325</td>\n",
       "      <td>19.59</td>\n",
       "      <td>28.11</td>\n",
       "      <td>212.0</td>\n",
       "      <td>21.604906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359225</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.091530</td>\n",
       "      <td>0.021553</td>\n",
       "      <td>0.05504</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.08760</td>\n",
       "      <td>0.102625</td>\n",
       "      <td>0.2075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>357.0</td>\n",
       "      <td>12.146524</td>\n",
       "      <td>1.780512</td>\n",
       "      <td>6.981</td>\n",
       "      <td>11.080</td>\n",
       "      <td>12.200</td>\n",
       "      <td>13.37</td>\n",
       "      <td>17.85</td>\n",
       "      <td>357.0</td>\n",
       "      <td>17.914762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>357.0</td>\n",
       "      <td>0.079442</td>\n",
       "      <td>0.013804</td>\n",
       "      <td>0.05521</td>\n",
       "      <td>0.070090</td>\n",
       "      <td>0.07712</td>\n",
       "      <td>0.085410</td>\n",
       "      <td>0.1486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean radius                                                      \\\n",
       "                count       mean       std     min     25%     50%    75%   \n",
       "diagnosis                                                                   \n",
       "0               212.0  17.462830  3.203971  10.950  15.075  17.325  19.59   \n",
       "1               357.0  12.146524  1.780512   6.981  11.080  12.200  13.37   \n",
       "\n",
       "                 mean texture             ... worst symmetry          \\\n",
       "             max        count       mean  ...            75%     max   \n",
       "diagnosis                                 ...                          \n",
       "0          28.11        212.0  21.604906  ...       0.359225  0.6638   \n",
       "1          17.85        357.0  17.914762  ...       0.298300  0.4228   \n",
       "\n",
       "          worst fractal dimension                                         \\\n",
       "                            count      mean       std      min       25%   \n",
       "diagnosis                                                                  \n",
       "0                           212.0  0.091530  0.021553  0.05504  0.076302   \n",
       "1                           357.0  0.079442  0.013804  0.05521  0.070090   \n",
       "\n",
       "                                      \n",
       "               50%       75%     max  \n",
       "diagnosis                             \n",
       "0          0.08760  0.102625  0.2075  \n",
       "1          0.07712  0.085410  0.1486  \n",
       "\n",
       "[2 rows x 240 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancerDeMamaDF.groupby(CLASSE).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimento = Experiments(cancerDeMamaDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo da informação mútua de cada atributo em relação à classe alvo\n",
    "\n",
    "Para verificar quais atributos mais influenciam a classe alvo realizamos o cálculo de entropia para cada atributo.  A entropia é uma métrica de mede a desorganização dos dados. A informação mútua, por sua vez, mede a correlação entre os dados, e utiliza da entropia em seu cálculo. Quanto maior o valor da entropia, maior a desorganização dos dados dos conjuntos comparados, e portanto, menor a correlação entre eles.\n",
    "\n",
    "Aplicado ao problema deste trabalho verificaremos a informação mútua para determinar quais atributos são mais correlatos a classe alvo. Como explicado anteriormente, a informação mútua é inversamente proporcional à correlação, ou seja, os atributos mais relacionados à classe alvo são aqueles com informação mútua mais baixa.\n",
    "\n",
    "A tabela abaixo mostra o resultado do experimento, em ordem crescente, sendo que as informações mútuas dos atributos variam entre 0 e 0.402583. Os cinco atributos mais influentes segundo essa métrica são texture_se,\tfractal_dimension_mean, smoothness_se, symmetry_se e fractal_dimension_se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texture error</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>area error</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst perimeter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.012196</td>\n",
       "      <td>0.014226</td>\n",
       "      <td>0.038027</td>\n",
       "      <td>0.06547</td>\n",
       "      <td>0.070875</td>\n",
       "      <td>0.074715</td>\n",
       "      <td>0.079877</td>\n",
       "      <td>0.093198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338584</td>\n",
       "      <td>0.360532</td>\n",
       "      <td>0.366147</td>\n",
       "      <td>0.374871</td>\n",
       "      <td>0.404641</td>\n",
       "      <td>0.437821</td>\n",
       "      <td>0.441677</td>\n",
       "      <td>0.452804</td>\n",
       "      <td>0.463288</td>\n",
       "      <td>0.473034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   texture error  mean fractal dimension  symmetry error  smoothness error  \\\n",
       "0       0.000787                0.005781        0.012196          0.014226   \n",
       "\n",
       "   fractal dimension error  worst fractal dimension  mean symmetry  \\\n",
       "0                 0.038027                  0.06547       0.070875   \n",
       "\n",
       "   compactness error  mean smoothness  worst symmetry  ...  area error  \\\n",
       "0           0.074715         0.079877        0.093198  ...    0.338584   \n",
       "\n",
       "   mean area  mean radius  mean concavity  mean perimeter  \\\n",
       "0   0.360532     0.366147        0.374871        0.404641   \n",
       "\n",
       "   worst concave points  mean concave points  worst radius  worst area  \\\n",
       "0              0.437821             0.441677      0.452804    0.463288   \n",
       "\n",
       "   worst perimeter  \n",
       "0         0.473034  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimento.mutual_entopy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando o impacto da remoção de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada cédula mostra as imagem que foram geradas e comparadas em conjuto. A cédula abaixo contém a árvore de decisão sem remoção de atributos, ela foi mantida nas comparações\n",
    "\n",
    "Foi utilizada a árvore de decisão com o parametro min_samples_split = 0.0002, porque a mesma apresentou o melhor resultado com relação min_samples_split = 0.25 e min_samples_split = 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusões\n",
    "\n",
    "Não houve diferenças nas árvores de decisões ao remover:\n",
    "- concavity_mean e concave points_mean\n",
    "- area_mean e perimeter_mean\n",
    "- perimeter_se e perimeter_se\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento de comparação entre duas representações da base pelo melhor método de árvore de decisão identificado via gridsearch\n",
    "\n",
    "Foram definidas duas representações: a primeira com todos os atributos e a segunda excluídos alguns atributos. O objetivo deste experimento é verificar se a remoção desses atributos impacta o resultado, e caso não haja impacto, pode-se reduzir a dimensão da base para criação de modelos futuros.\n",
    "\n",
    "Os atributos removidos foram concavity_mean, concave points_mean, area_mean, perimeter_mean, perimeter_se, perimeter_se. Eles foram selecionados por serem correlationados com outros atributos do dataset.\n",
    "\n",
    "Para a representação de todos os atributos obtivemos como min_sample_split = 0.25, e para a representação excluídos alguns atributos min_sample_split = 0.0002.\n",
    "\n",
    " Com todos os atributos\n",
    "best parameters: \n",
    "{'min_samples_split': 0.25, 'random_state': 1}\n",
    "\n",
    "classification_report:\n",
    "\n",
    "|              |   precision |   recall |   f1-score |   support |\n",
    "|:-------------|------------:|---------:|-----------:|----------:|\n",
    "| B            |        0.96 |     0.99 |       0.97 |        67 |\n",
    "| M            |        0.98 |     0.94 |       0.96 |        47 |\n",
    "| accuracy     |        0.96 |     0.96 |       0.96 |       114 |\n",
    "| macro avg    |        0.97 |     0.96 |       0.96 |       114 |\n",
    "| weighted avg |        0.97 |     0.96 |       0.96 |       114 |\n",
    "\n",
    "confusion matrix:\n",
    "\n",
    "|        |   B_pred |   M_pred |\n",
    "|:-------|---------:|---------:|\n",
    "| B_true |       66 |        1 |\n",
    "| M_true |        3 |       44 |\n",
    "\n",
    "Sem alguns atributos\n",
    "best parameters: \n",
    "{'min_samples_split': 0.0002, 'random_state': 1}\n",
    "\n",
    "classification_report:\n",
    "\n",
    "|              |   precision |   recall |   f1-score |   support |\n",
    "|:-------------|------------:|---------:|-----------:|----------:|\n",
    "| B            |        0.97 |     0.93 |       0.95 |        67 |\n",
    "| M            |        0.9  |     0.96 |       0.93 |        47 |\n",
    "| accuracy     |        0.94 |     0.94 |       0.94 |       114 |\n",
    "| macro avg    |        0.93 |     0.94 |       0.94 |       114 |\n",
    "| weighted avg |        0.94 |     0.94 |       0.94 |       114 |\n",
    "\n",
    "confusion matrix:\n",
    "\n",
    "|        |   B_pred |   M_pred |\n",
    "|:-------|---------:|---------:|\n",
    "| B_true |       62 |        5 |\n",
    "| M_true |        2 |       45 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrando os melhores parâmetros para SVM via grid search\n",
    "O dataset foi dividido em 80% treino e 20% teste, sendo o dataset de treino utilizado para encontrar os melhores parâmetros e o dataset de testes para validar o modelo considerado o melhor <img src=\"img/cv-gridsearch.jpeg\" alt=\"Esquema de divisão do dataset para encontrar os melhores parâmetros e testar o melhor método encontrado\">\n",
    "\n",
    "Para encontrar os melhores parâmetros do método SVM para o dataset foi feita uma _grid search_ utilizando _cross validation_ do tipo K-fold para k = 5. As configurações testadas foram combinações dos parâmetros kernel = {linear, rbf} e C = {1, 10, 100, 1000}. O melhor resultado foi o classificador SVM de C = 1 e kernel linear.\n",
    "\n",
    "Encontrado o melhor modelo foi feito o teste com dados não vistos anteriormente.\n",
    "\n",
    "## Avaliação do método\n",
    "\n",
    "Para o melhor modelo encontrado obtivemos os seguintes resultados:\n",
    "\n",
    "\n",
    "|              |   precision |   recall |   f1-score |   support |\n",
    "|:-------------|------------:|---------:|-----------:|----------:|\n",
    "| B            |        0.98 |     0.94 |       0.96 |        67 |\n",
    "| M            |        0.92 |     0.98 |       0.95 |        47 |\n",
    "| accuracy     |        0.96 |     0.96 |       0.96 |       114 |\n",
    "| macro avg    |        0.95 |     0.96 |       0.96 |       114 |\n",
    "| weighted avg |        0.96 |     0.96 |       0.96 |       114 |\n",
    "\n",
    "<p style=\"text-align: center;\"> Precision, Recall, F1-score e Support por classe </p>\n",
    "\n",
    "|        |   B_pred |   M_pred |\n",
    "|:-------|---------:|---------:|\n",
    "| B_true |       63 |        4 |\n",
    "| M_true |        1 |       46 |\n",
    "\n",
    "<p style=\"text-align: center;\"> Matrix de confusão </p>\n",
    "\n",
    "Os resultados acima mostram que a métrica precisão é mais alta para predizer os tumores do tipo benigno enquanto a métrica revocação é mais alta para os tumores malignos. Estes resultados são satisfatórios, pois indicam que dos tumores malignos, 98% foram preditos corretamente, sendo que do que foi predito como maligno 92% era de fato maligno. É um modelo que erra mais indicando que um tumor benigno é maligno do que ao contrário, o que cumpre o papel mais importante de detectar corretamente os tumores malignos. Abaixo a matriz de confusão que confirma as conclusões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação de métodos via gridsearch\n",
    "Foram comparados 4 modelos com variação de parâmetros:\n",
    "- **SVM Linear**: Variação do custo: $2^{-1}, 2^1,2^3,2^5$\n",
    "- **SVM RBF**: Variação do custo: $2^{-1}, 2^1,2^3$ e, para cada variação do custo, você deverá variar o Gama: $2^{-1}, 2^1,2^3$\n",
    "- **KNN**: Variação do k: $2^2,2^4,2^6,2^8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for LinearSVC.\n",
      "Running GridSearchCV for DecisionTreeClassifier.\n",
      "Running GridSearchCV for KNeighborsClassifier.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>{'min_samples_split': 0.0002, 'random_state': 1}</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.913580</td>\n",
       "      <td>0.940125</td>\n",
       "      <td>0.032291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.007190</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>{'min_samples_split': 0.25, 'random_state': 1}</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.919531</td>\n",
       "      <td>0.068895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.007197</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>{'min_samples_split': 0.5, 'random_state': 1}</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.915500</td>\n",
       "      <td>0.057498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>{'n_neighbors': 16}</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.925165</td>\n",
       "      <td>0.101287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913580</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.921065</td>\n",
       "      <td>0.080752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>{'n_neighbors': 64}</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.908055</td>\n",
       "      <td>0.118597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>{'n_neighbors': 256}</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.877499</td>\n",
       "      <td>0.139847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.037412</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>{'C': 0.5}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.922750</td>\n",
       "      <td>0.092689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.032821</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>{'C': 2}</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.907067</td>\n",
       "      <td>0.093287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.033194</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>{'C': 32}</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.874517</td>\n",
       "      <td>0.115243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.032546</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>{'C': 8}</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.872508</td>\n",
       "      <td>0.153613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 estimator  mean_fit_time  std_fit_time  mean_score_time  \\\n",
       "0   DecisionTreeClassifier       0.007320      0.000483         0.001272   \n",
       "4   DecisionTreeClassifier       0.007190      0.000542         0.001282   \n",
       "5   DecisionTreeClassifier       0.007197      0.000886         0.001599   \n",
       "1     KNeighborsClassifier       0.001640      0.000044         0.003278   \n",
       "3     KNeighborsClassifier       0.001802      0.000120         0.003350   \n",
       "6     KNeighborsClassifier       0.001699      0.000106         0.003771   \n",
       "8     KNeighborsClassifier       0.001890      0.000413         0.006008   \n",
       "2                LinearSVC       0.037412      0.004608         0.001593   \n",
       "7                LinearSVC       0.032821      0.001327         0.001398   \n",
       "9                LinearSVC       0.033194      0.002773         0.001413   \n",
       "10               LinearSVC       0.032546      0.001185         0.001343   \n",
       "\n",
       "    std_score_time                                            params  \\\n",
       "0         0.000075  {'min_samples_split': 0.0002, 'random_state': 1}   \n",
       "4         0.000113    {'min_samples_split': 0.25, 'random_state': 1}   \n",
       "5         0.000329     {'min_samples_split': 0.5, 'random_state': 1}   \n",
       "1         0.000181                               {'n_neighbors': 16}   \n",
       "3         0.000152                                {'n_neighbors': 4}   \n",
       "6         0.000195                               {'n_neighbors': 64}   \n",
       "8         0.001126                              {'n_neighbors': 256}   \n",
       "2         0.000225                                        {'C': 0.5}   \n",
       "7         0.000108                                          {'C': 2}   \n",
       "9         0.000137                                         {'C': 32}   \n",
       "10        0.000108                                          {'C': 8}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.880000           0.929577           0.931507   \n",
       "4            0.733333           0.916667           0.931507   \n",
       "5            0.758621           0.916667           0.914286   \n",
       "1            0.628571           0.944444           0.944444   \n",
       "3            0.687500           0.944444           0.944444   \n",
       "6            0.564103           0.909091           0.931507   \n",
       "8            0.488889           0.864198           0.923077   \n",
       "2            0.666667           0.971429           0.958904   \n",
       "7            0.647059           0.971429           0.944444   \n",
       "9            0.814815           0.931507           0.878788   \n",
       "10           0.846154           0.931507           0.929577   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0            0.918033           0.949153           0.989011   \n",
       "4            0.918033           0.965517           0.989011   \n",
       "5            0.945455           0.965517           0.966292   \n",
       "1            0.918033           0.983051           0.989011   \n",
       "3            0.915254           0.982456           0.977778   \n",
       "6            0.888889           0.950820           0.989011   \n",
       "8            0.794521           0.906250           0.967742   \n",
       "2            0.852941           0.935484           0.978261   \n",
       "7            0.892308           0.878788           0.967742   \n",
       "9            0.903226           0.964286           0.902439   \n",
       "10           0.903226           0.878788           0.978261   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0            0.936709           0.988506           0.964706   \n",
       "4            0.925000           0.977273           0.886076   \n",
       "5            0.923077           0.952381           0.886076   \n",
       "1            0.951220           0.977273           0.939759   \n",
       "3            0.951220           0.954545           0.913580   \n",
       "6            0.951220           0.966292           0.942529   \n",
       "8            0.953488           0.967033           0.945055   \n",
       "2            0.964706           0.965517           0.946237   \n",
       "7            0.951220           0.988764           0.902439   \n",
       "9            0.561404           0.857143           0.945055   \n",
       "10           0.942529           0.428571           0.900000   \n",
       "\n",
       "    split9_test_score  mean_test_score  std_test_score  \n",
       "0            0.913580         0.940125        0.032291  \n",
       "4            0.953488         0.919531        0.068895  \n",
       "5            0.926829         0.915500        0.057498  \n",
       "1            0.976744         0.925165        0.101287  \n",
       "3            0.939759         0.921065        0.080752  \n",
       "6            0.988506         0.908055        0.118597  \n",
       "8            0.966292         0.877499        0.139847  \n",
       "2            0.988506         0.922750        0.092689  \n",
       "7            0.926829         0.907067        0.093287  \n",
       "9            0.988506         0.874517        0.115243  \n",
       "10           0.988506         0.872508        0.153613  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimento.gridsearch_svm_tree_knn().sort_values('estimator')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
